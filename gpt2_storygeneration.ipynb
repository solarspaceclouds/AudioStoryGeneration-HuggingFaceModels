{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Story Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 665/665 [00:00<00:00, 1.39MB/s]\n",
      "model.safetensors: 100%|██████████| 548M/548M [00:15<00:00, 34.8MB/s] \n",
      "generation_config.json: 100%|██████████| 124/124 [00:00<00:00, 970kB/s]\n",
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.43MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.85MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 1.42MB/s]\n",
      "/home/solarspaceclouds/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:430: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a land far, far away, the world was a place of great beauty and great danger. The world of the gods was the land of darkness and darkness. And the darkness of this world, which was far from the light of day, was not the place where the sun and the moon met. It was in the midst of all the worlds, and it was there that the stars and all that were in them met, that they were all in one place.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Define the beginning of a story as input\n",
    "input_text = \"Once upon a time in a land far, far away,\"\n",
    "\n",
    "# Encode the input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "# Generate text continuation\n",
    "output_ids = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2, early_stopping=True)\n",
    "\n",
    "# Decode the generated text\n",
    "story = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(story)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sci fi story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Last Starship\n",
      "\n",
      "Chapter 1: The Awakening\n",
      "In a galaxy far, far away, a lone starship drifted silently through the cosmos. Aboard the vessel, a lone astronaut stirred from a long slumber. He was a young man, and he was the only one who had ever been able to see the stars.\n",
      "The young astronaut was an old man. His name was John. The name of the man was not his. It was his name. John was born in the year of his birth, in a small town in northern California. In the years that followed, he would grow up in an orphanage, where he learned to read and write. But he never had a chance to learn to write, because he had been raised by a single mother. And he didn't know how to do it. So he began to study. When he finished his studies, his mother died. That was when he started to think about his future. What would he do? He would go to college, study, write and become a writer. Then he'd go back to his home town, California, to live with his father. There, John would spend his days reading and writing. Eventually, when his parents died, they moved to a new home. They had two children, but they were still together. One of them was named John, the other John the Gemini. Their lives were different. Both were born with a broken heart. Neither had the strength to survive. Each had to find a way to make it through life. As John grew older, though, things began changing. For the first time, there was hope. At the age of twenty-one, after a short stint in prison, she was released. She was given a job as a nurse. Her job was to help John get through his first year in college. After that, her job became a full-time job. Now, as she worked, it was her responsibility to keep her family together, even if it meant working for the government. This was what she did. On the day she left, however, that job changed. \"I'm going to be a doctor,\" she said. I asked her what that meant. To her, I said, \"You're going back home to your parents.\" She said she would be back. We talked for a while. Finally, we agreed to meet at a restaurant. My mother was there. Our mother had just been released from prison. All of a sudden, my father came to visit. Before long, our father was gone. No one knew what had happened to him. Instead, all of that changed when John came home from college to work. Soon, everything changed for him, for his family, or for himself. Suddenly, something changed in his life, too. Something that he hadn't known about. Someone who was going through a difficult time. Who was in need of help. Somebody who needed to get out of prison and get back into his own life and to have a better life for everyone. People who were struggling with their own problems. Those who felt like they had no place in their lives. These people were going into a place where they could be themselves. Not just a person, like John and his friends. Like John himself, who would never be able, ever to go home again. Because of this, people who knew him were afraid to come to the United States. Many of those people had never been to America. Some of these people would have never come back, if they knew that they would. Others would not have come. Even if John had come home, many of their friends would still be there, waiting for them. If they did not come, then they wouldn't be here. Most of all, these friends and family would feel like nothing had changed, no one had cared about them, just that John's life had become so much better. Everyone knew this. Every single person who came into contact with John knew he could never go. Nobody knew how he felt. Only John could tell them that. Just as John felt that his situation was so different from his past life that it would take him years to change, so too did he feel that there would always be someone who could help him change. Maybe he did, maybe he just didn. Whatever it is, this was something that had always been there for John for so long. Sometimes, you just have to take it for what it really is. You have no idea.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Define the beginning of a sci-fi story as input and indicate chapters\n",
    "input_text = \"Title: The Last Starship\\n\\nChapter 1: The Awakening\\nIn a galaxy far, far away, a lone starship drifted silently through the cosmos. Aboard the vessel, a lone astronaut stirred from a long slumber.\"\n",
    "\n",
    "# Encode the input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "# Generate text continuation\n",
    "output_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_length=1000, # Increase max_length for a longer story\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    early_stopping=True,\n",
    "    temperature=0.8, # Adjust temperature for creativity\n",
    "    top_k=50, # Top-k sampling\n",
    "    top_p=0.95 # Top-p (nucleus) sampling\n",
    ")\n",
    "\n",
    "# Decode the generated text\n",
    "story = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(story)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to generate chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As the astronaut discovered the hidden message in the starship's mainframe, the true nature of their mission began to unravel. \n",
      "\n",
      "Chapter 2: The Revelation\n",
      "The astronaut pondered over the cryptic message, feeling the weight of its implications. \"I'm here to save humanity,\" he finally said. The message was still in his mind.\n",
      ". It had become a recurring theme, but only for a few hours. As he continued to ponder over it, he noticed his own thoughts seemed to shift. He realized that the message had been the same for two years and that he had seen no signs of it. One year, his ship was being attacked by a group of aliens. Then, they attacked the ship with a nuclear bomb, causing the shuttle to crash. Now, it was his turn to question the meaning of the messages, and whether they were true. If they really were, then perhaps they had a hidden purpose. But if they didn't, why not tell the truth? What he would have to do with the spacecraft if he found out?\n",
      "\"Are you sure?\" The astronaut asked. His expression was blank. There was no one to answer him. Instead, some of his crewmates moved around the space station, searching for clues, eventually finding clues in some unknown area. They began searching, hoping to find clues about the crew and the mission. And they found something they would never have expected to hear from the last astronaut: a message from a woman. She had appeared in a vision, with her own story of being rescued by humanity. In a way, she could have been a human, even if the astronauts had never met her. A message sent from space, as a metaphor for the future of humanity, would be a powerful reminder for his group. Even though he could not see the words, so far there was little he couldn't understand. When they arrived at the spaceship, one of them was already in tears. Looking up, a man in black saw the man's face, in shock and horror. So close he almost felt like the tears had stopped. What could the other astronaut know about his fellow astronauts? He quickly realized what was happening. Some of him had lost his consciousness and was now in pain. Only his face. Not his hands. Most of what he saw would not be seen by him, not by those who were there, nor would it be in public. Perhaps, if only his other crewmembers had known. Maybe\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Summarized context from the end of Chapter 1 and start of Chapter 2\n",
    "input_text = \"As the astronaut discovered the hidden message in the starship's mainframe, the true nature of their mission began to unravel. \\n\\nChapter 2: The Revelation\\nThe astronaut pondered over the cryptic message, feeling the weight of its implications.\"\n",
    "\n",
    "# Encode the input text\n",
    "encoding = tokenizer.encode_plus(input_text, return_tensors='pt')\n",
    "\n",
    "# Extract input_ids and attention_mask\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "# Generate text continuation for Chapter 2\n",
    "output_ids = model.generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=500,  # Adjust as needed\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    do_sample=True,\n",
    "    temperature=0.8,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# Decode the generated text\n",
    "chapter_2 = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(chapter_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The astronaut pondered over the cryptic message, feeling the weight of its implications. [Insert the actual ending text of Chapter 2 here]\n",
      "\n",
      "Chapter 2 Edit\n",
      " (Episode 22 - 2:44 PM)\n",
      ".\n",
      " \"In the name of the LORD, the King, and the Father, I grant thee this blessing, my beloved one, in the presence of God, to forgive my sins, that I may never again sin.\"\n",
      " - Jesus. It's all so nice. I can't believe I just read that. So much so that this is all being done for a cause, not for some good cause. (The two are still in sync, but he says something like this to me now) \"And, O God! It is only God who blesseth me in my days, as it is in thy days. In thy sight thou hast shown me the way. To the world, also, there shall be weeping and gnashing of teeth. The world shall see my body and see thy face. And the earth shall tremble and quake with the sound of thy voice, till thou shallest see the light of all things. For the day of my ascension shall come, then, when I shall have finished my work and shall live again. But when that day comes, thou shalt not leave the house of Israel, for I will not enter it. Yet I remain in it, like the serpent of old, a serpent that is with a sword in its mouth: and my hand shall take the sword, which shall bring forth life. Thy works shall not be done, though they are in accordance with my will. Thou shalt never set an end to my evil deeds, nor shall I set a beginning to thy works. If thou girdest them, they shall never harm thee. Then shall my soul return to thee, from whence I came, with all its glory. \" - The King. He does not want to tell the whole story, because he feels that the story is so obvious that he will have to ask the questions that make up the entire story. Well, he doesn't want the book to be too dramatic. Oh, you don't have that option. You do. Either you take it or you tell it in that way that would make it more clear. That's the problem, is that you're giving it to the big guys. One of them is a guy with bad feelings and there's no reason he should take that as\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Assuming 'chapter_2_end' contains the last part of the text from Chapter 2\n",
    "chapter_2_end = \"The astronaut pondered over the cryptic message, feeling the weight of its implications. [Insert the actual ending text of Chapter 2 here]\"\n",
    "\n",
    "# Encode the input text\n",
    "encoding = tokenizer.encode_plus(chapter_2_end, return_tensors='pt')\n",
    "\n",
    "# Extract input_ids and attention_mask\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "# Generate text continuation\n",
    "output_ids = model.generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=500,  # Adjust as needed\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    do_sample=True,\n",
    "    temperature=0.8,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# Decode the generated text\n",
    "chapter_continuation = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(chapter_continuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
